{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "import tqdm\n",
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(filename):\n",
    "    \"\"\"Load MNIST images\n",
    "    Returns:\n",
    "      4 matrices : 'training_images', 'training_labels', 'test_images', 'test_labels'\n",
    "    \"\"\"\n",
    "    with open(filename,'rb') as f:\n",
    "        mnist = pickle.load(f)\n",
    "    return mnist[\"training_images\"], mnist[\"training_labels\"], mnist[\"test_images\"], mnist[\"test_labels\"]\n",
    "\n",
    "def preproccess_images(X, Y, split):\n",
    "    \"\"\"Convert to binary format image, extracts only 0 and 1\n",
    "    classes from train dataset.\n",
    "    \"\"\"\n",
    "    # convert image from range {0,1,...,255} to range {0,1}\n",
    "    X = (X>127).astype(np.uint8)\n",
    "    # get indecies of images, which represent 0 and 1\n",
    "    indecies_of_zeros = np.where(Y == 0)\n",
    "    indecies_of_ones = np.where(Y == 1)\n",
    "    # amount of 0 and 1 digits in 'X_train'\n",
    "    number_zeros = len(indecies_of_zeros[0])\n",
    "    number_ones = len(indecies_of_ones[0])\n",
    "    # get 1 and 0 digits from 'X_train'\n",
    "    zeros = X[indecies_of_zeros,:].reshape((-1,28,28))\n",
    "    ones = X[indecies_of_ones,:].reshape((-1,28,28))\n",
    "    n_samples = min(number_ones,number_zeros)\n",
    "    train_numbers = int(split*n_samples)\n",
    "    zeros_train = zeros[:train_numbers,...]\n",
    "    zeros_test = zeros[train_numbers:n_samples,...]\n",
    "    ones_train = ones[:train_numbers,...]\n",
    "    ones_test = ones[train_numbers:n_samples,...]\n",
    "    X_train = np.concatenate([zeros_train,ones_train], axis=0)\n",
    "    Y_train = np.concatenate((np.zeros((train_numbers,1)),np.ones((train_numbers,1))), axis=0).astype(np.uint8)    \n",
    "    return X_train, Y_train\n",
    "\n",
    "######\n",
    "\n",
    "def generate_aposterior_probabilities(n_samples,n_classes):\n",
    "    \"\"\"Generate a matrix with shape (n_samples,n_classes), where\n",
    "    sum along axis=1 = 1. p(k|Xz)\n",
    "    \"\"\"\n",
    "    rand_matrix = np.random.randint(low=0, high=5000,size=(n_samples,n_classes))\n",
    "    sum_along_row = np.repeat(rand_matrix.sum(axis=1).reshape((-1,1)),repeats=2, axis=1)\n",
    "    prob_matrix = rand_matrix/sum_along_row\n",
    "    return prob_matrix\n",
    "\n",
    "\n",
    "def aprior_probabilities(probability_histogram):\n",
    "    \"\"\"calculate p(k)\n",
    "    \"\"\"\n",
    "    return probability_histogram.mean(axis=0)\n",
    "\n",
    "\n",
    "\n",
    "def calculate_parameters(X, aposterior_probs):\n",
    "    \"\"\"Calculate p_kij\n",
    "    Args:\n",
    "        X : a matrix (8982,28,28)\n",
    "        aposterior_probs : a matrix (8982,2)\n",
    "    Returns :\n",
    "    a matrix of probabilities\n",
    "    \"\"\"\n",
    "    znam = aposterior_probs.sum(axis=0)\n",
    "    znam = np.expand_dims(znam,axis=1)\n",
    "    znam = np.repeat(znam,repeats=28*28, axis=1).reshape((2,28,28))\n",
    "    probs = np.expand_dims(aposterior_probs.T,axis=2)\n",
    "    probs = np.repeat(probs,repeats=28*28, axis=2).reshape((2,X.shape[0],28,28))\n",
    "    X = np.expand_dims(X,axis=0)\n",
    "    X = np.repeat(X,repeats=2,axis=0)\n",
    "    return np.multiply(X,probs).sum(axis=1)/znam\n",
    "\n",
    "\n",
    "def calculate_conditional_probs(X, parameters):\n",
    "    \"\"\" p_kij\n",
    "    X - (8982,28,28)\n",
    "    parameters - (2,28,28)\n",
    "    \n",
    "    Returns : \n",
    "    a matrix of shape (8292,2)\n",
    "    \"\"\"\n",
    "    parameters = np.expand_dims(parameters, axis=0)\n",
    "    parameters = np.repeat(parameters,repeats=X.shape[0], axis=0)\n",
    "    parameters = parameters.reshape((parameters.shape[0],parameters.shape[1],-1))\n",
    "    X = np.expand_dims(X, axis=1)\n",
    "    X = np.repeat(X,repeats=2, axis=1)\n",
    "    X = X.reshape((X.shape[0],X.shape[1],-1))\n",
    "    power1 = np.power(parameters,X).prod(axis=-1)\n",
    "    power2 = np.power(1 - parameters,(1 - X)).prod(axis=-1)\n",
    "    return np.multiply(power1, power2)\n",
    "\n",
    "\n",
    "def calculate_aposterior(conditions, aprior_probs):\n",
    "    \"\"\"\n",
    "    conditions - (8982,2)\n",
    "    aprior_probs - (2,)\n",
    "    Returns :\n",
    "    a matrix with shape (8292,2)\n",
    "    \"\"\"\n",
    "    znam = conditions[:,0]*aprior_probs[0] + conditions[:,1]*aprior_probs[1]\n",
    "    aposterior0 = (conditions[:,0]*aprior_probs[0])/znam\n",
    "    aposterior1 = (conditions[:,1]*aprior_probs[1])/znam\n",
    "    return np.stack((aposterior0,aposterior1),axis=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load mnist dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape =  (8292, 28, 28)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAaElEQVR4nM2RQRLAIAgDA9P/fzk9tAoEPHamuckmGhX4XmRde2ZqcDTxAA2wRL0lEnVlmQ5nBt2Qz3TRljSIFqQCSZYgT4U0Oe6akq3OhlbCfK1X98eN29vmL7OK6jBqUFHtSIydf6QbLhkZHfOBK9sAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0xB6CE090>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAIN_TEST_SPLIT = 0.7\n",
    "filename = \"./mnist.pkl\"\n",
    "num_classes = 2\n",
    "epochs = 20\n",
    "##############\n",
    "# in the further parts of lab we use only train part of MNIST dataset \n",
    "X, Y, _, _ = load(filename)\n",
    "# convert to binary format, extract only 0 and 1 classes\n",
    "X_train, Y_train = preproccess_images(X,Y, TRAIN_TEST_SPLIT)\n",
    "print(\"X_train.shape = \",X_train.shape)\n",
    "# example \n",
    "Image.fromarray(X_train[234,:,:]*255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aposterior_probs.shape =  (8292, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:41<00:00,  2.06s/it]\n"
     ]
    }
   ],
   "source": [
    "for epoch in tqdm.tqdm(range(epochs)):\n",
    "    if epoch == 0 :\n",
    "        # p(k|Xz), shape=(8982,2)\n",
    "        aposterior_probs = generate_aposterior_probabilities(X_train.shape[0], num_classes)\n",
    "        print(\"aposterior_probs.shape = \",aposterior_probs.shape)\n",
    "    # p(k), shape = (2,)\n",
    "    aprior_probs = aprior_probabilities(aposterior_probs)\n",
    "    # p_kij, shape= (2,28,28)\n",
    "    parameters = calculate_parameters(X_train,aposterior_probs)\n",
    "    # p(Xz|k), shape=(8982,2)\n",
    "    conditions = calculate_conditional_probs(X_train, parameters)\n",
    "    # p(k|Xz), shape=(8982,2)\n",
    "    aposterior_probs = calculate_aposterior(conditions,aprior_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABKElEQVR4nLXSwU7CQBAG4JnZ3TYILVCVSGrUcPL9n8aDFw4QFKqwFtpuuzseEAotHjw4t90vmcw/GYB/KWy/+BKi6ASBcpCbbGccA4CskbxePA44T5M1WwdniECqezOAL0rB7r9qZGD0gojtR5lXlgEAqG7LlmU4CkSRpsZBE5n9aNQt9CavuInI3Ilj0itd/qQ5QWAIn6JskRQOmoiAFD+KZK4raCEzdJ775fTdcBsB5d2E1q/aQRsRe5N+NX2zfAn98QPql+xkwuOGUAzvr81yZi8hdaNbfzXTRNgaiPxwFNr5wihB2EBUV8OBypafVipCPG8rVC/0eSNSUAKPt7BHIulJ3ho0FZ7cxmEgLrfJFtCtd6YOiocg0pOEiEVu6g01Cn+DP9Y3sul7avrqBLMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0xB746490>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image.fromarray((parameters[0,:,:]*255).astype(np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABrElEQVR4nLXSW3OaUBAH8D2Hw4FyEUlBIRoxNv3+H8iYekm8AWoNCIfb9qESM33qdKb7tDO/2dmd2T/AfynyuSdACCAi/omEMm50TJ0Wyfs5LerPSCTFcAcPQ5unu+X87Zg1AMBa+2J5k8ljz2blwe1yEgq8ITf8ydPE1SVQHaBCZGXdImFaL/g2tuGYF8zk3vkUnW+o2v5odNdE20Mie0Ol5y92RYuS7j4M7SZarLapeoLAdGy5PYhwyx/2WDidLU6lhrZrGOYNNWfgaclq+hIKLM33i85U3iLt9D2r3s9eNnlN5LpGREoJAgUAoJbrqOlqHmZlg1RRpKaoCMBvlLt3BsTr6FIiMN3q8vySVnhFbli8OMRJBYTpzsBlWXzO252yqtA8zxpCZeN+HHSbQxSLj4MQKZF0HanuBd/v5f16eypabPK8UfoBZtz2g74cbV43Sd1icYxT58kcp9z8asB+NVvG+cfLRLh0O64nRE0xeZtN59ukgo/J8FnGyjP04udu/vxjHV8qvCWBaf3RxHdYsl+97uO0vKboGhNKuapxqRa5EHXzd9n85/oFTgrLTtZvWUMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0xB6A0550>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image.fromarray((parameters[1,:,:]*255).astype(np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
